{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSbLnreI5wof",
        "outputId": "0db6fd5f-e2e9-4e56-a178-73e34410172b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Downloading faker-37.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MOCK DATASETS\n",
        "import pandas as pd\n",
        "import random\n",
        "from faker import Faker\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Generate 100 unique patient IDs\n",
        "patient_ids = [f'P{str(i).zfill(4)}' for i in range(1, 101)]\n",
        "\n",
        "# Generate demographic dataset\n",
        "patient_data = {\n",
        "    \"Patient_ID\": patient_ids,\n",
        "    \"First_Name\": [fake.first_name() for _ in range(100)],\n",
        "    \"Last_Name\": [fake.last_name() for _ in range(100)],\n",
        "    \"Date_of_Birth\": [fake.date_of_birth(minimum_age=30, maximum_age=90) for _ in range(100)],\n",
        "    \"Gender\": [random.choice([\"Male\", \"Female\", \"Other\"]) for _ in range(100)],\n",
        "    \"Address\": [f\"{fake.building_number()} {fake.street_name()}, {fake.city()}, {fake.state_abbr()} {fake.zipcode()}\" for _ in range(100)],\n",
        "    \"Insurance_Information\": [random.choice([\"Medicare\", \"Medicaid\", \"Private\", \"Uninsured\"]) for _ in range(100)]\n",
        "}\n",
        "df_patient = pd.DataFrame(patient_data)\n",
        "\n",
        "# Generate Diagnosis dataset\n",
        "\n",
        "# Link diagnoses with corresponding ICD-10 codes\n",
        "diagnoses = [\n",
        "    (\"Type 2 diabetes mellitus with hyperglycemia\", \"E11.65\"),\n",
        "    (\"Osteoarthritis\", \"M15.0\"),\n",
        "    (\"Mixed hyperlipidemia\", \"E78.2\"),\n",
        "    (\"Essential (primary) hypertension\", \"I10\"),\n",
        "    (\"Gastroesophageal reflux disease without esophagitis\", \"K21.9\"),\n",
        "    (\"Lumbar spondylosis\", \"M47.896\"),\n",
        "    (\"Asthma, unspecified\", \"J45.0\"),\n",
        "    (\"Mild cognitive impairment\", \"G31.\")\n",
        "]\n",
        "\n",
        "# Generate data\n",
        "diagnosis_data = {\n",
        "    \"Patient_ID\": random.choices(patient_ids, k=150),\n",
        "    \"Dx_Code\": [],\n",
        "    \"Dx_Description\": [],\n",
        "    \"Dx_Date\": [fake.date_between(start_date=\"-2y\", end_date=\"today\") for _ in range(150)]\n",
        "}\n",
        "\n",
        "# Assign diagnoses randomly\n",
        "for _ in range(150):\n",
        "    diagnosis = random.choice(diagnoses)\n",
        "    diagnosis_data[\"Dx_Code\"].append(diagnosis[1])\n",
        "    diagnosis_data[\"Dx_Description\"].append(diagnosis[0])\n",
        "\n",
        "df_diagnosis = pd.DataFrame(diagnosis_data)\n",
        "\n",
        "\n",
        "# Link procedures with corresponding CPT codes\n",
        "procedures = [\n",
        "    (\"Preventive exam for patient over 65\", \"99397\"),\n",
        "    (\"Preventive exam for new adult patient age 40-64\", \"99386\"),\n",
        "    (\"Established patient office visit (10-19 minutes)\", \"99212\"),\n",
        "    (\"Established patient office visit (20-29 minutes)\", \"99213\"),\n",
        "    (\"Automated urinalysis without microscopy\", \"81003\"),\n",
        "    (\"Influenza virus vaccine, inactivated\", \"90653\"),\n",
        "    (\"Cardiovascular stress testing\", \"93015\")\n",
        "]\n",
        "\n",
        "# Generate procedure dataset\n",
        "procedure_data = {\n",
        "    \"Patient_ID\": random.choices(patient_ids, k=150),\n",
        "    \"Procedure_Code\": [],\n",
        "    \"Procedure_Description\": [],\n",
        "    \"Procedure_Date\": [fake.date_between(start_date=\"-2y\", end_date=\"today\") for _ in range(150)]\n",
        "}\n",
        "\n",
        "# Assign procedures randomly while ensuring correct code-description mapping\n",
        "for _ in range(150):\n",
        "    procedure = random.choice(procedures)\n",
        "    procedure_data[\"Procedure_Code\"].append(procedure[1])\n",
        "    procedure_data[\"Procedure_Description\"].append(procedure[0])\n",
        "\n",
        "df_procedure = pd.DataFrame(procedure_data)\n",
        "\n",
        "\n",
        "# Generate Appointment dataset\n",
        "appointment_data = {\n",
        "    \"Patient_ID\": random.choices(patient_ids, k=150),  # Some patients have multiple appointments\n",
        "    \"Appointment_Date\": [fake.date_between(start_date=\"-1y\", end_date=\"today\") for _ in range(150)],\n",
        "    \"Appointment_Time\": [fake.time(pattern=\"%H:%M\") for _ in range(150)],\n",
        "    \"Location\": [random.choice([\"Clinic A\", \"Clinic B\", \"Clinic C\", \"Telehealth\"]) for _ in range(150)],\n",
        "    \"Appointment_Type\": [random.choice([\"New Patient\", \"Follow Up\", \"Sick Visit\"]) for _ in range(150)],\n",
        "    \"Appointment_Status\": [random.choice([\"Checked-In\", \"Cancelled\", \"No-Show\"]) for _ in range(150)]\n",
        "}\n",
        "df_appointment = pd.DataFrame(appointment_data)\n",
        "\n",
        "# Save datasets to CSV files\n",
        "df_patient.to_csv(\"patient_dataset.csv\", index=False)\n",
        "df_diagnosis.to_csv(\"diagnosis_dataset.csv\", index=False)\n",
        "df_procedure.to_csv(\"procedure_dataset.csv\", index=False)\n",
        "df_appointment.to_csv(\"appointment_dataset.csv\", index=False)\n",
        "\n",
        "print(\"All datasets successfully created as CSV files!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0pjaLMx5JYM",
        "outputId": "a63f12ab-2831-4fb7-9884-f2968c9c8549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All datasets successfully created as CSV files!\n"
          ]
        }
      ]
    }
  ]
}